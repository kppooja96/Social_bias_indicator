{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SOCIAL BIAS INDICATOR\n",
        "\n",
        "#### Pooja Kangokar Pranesh\n",
        "#### DS 690: Introduction to Natural Language Processing"
      ],
      "metadata": {
        "id": "H0HoIA_yTHb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "_lzZ_OVy-V57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!pip install -qq transformers\n",
        "!pip install -qq gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC2aNq8Br7He",
        "outputId": "cdb8660b-1f1b-4eb9-8a00-52730ef46d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from transformers import GPT2Model, GPT2Tokenizer\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "lrzqXv_er9lP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Standard Model"
      ],
      "metadata": {
        "id": "Gn_4FIUU-z-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleGPT2SequenceClassifier(nn.Module):\n",
        "    '''\n",
        "    This class loads the GPT2 Pretrained Model\n",
        "    '''\n",
        "    def __init__(self, hidden_size: int, num_classes:int ,max_seq_len:int, gpt_model_name:str):\n",
        "        super(SimpleGPT2SequenceClassifier,self).__init__()\n",
        "        self.gpt2model = GPT2Model.from_pretrained(gpt_model_name)\n",
        "        self.fc1 = nn.Linear(hidden_size*max_seq_len, num_classes)\n",
        "\n",
        "        \n",
        "    def forward(self, input_id, mask):\n",
        "        \n",
        "        gpt_out, _ = self.gpt2model(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
        "        batch_size = gpt_out.shape[0]\n",
        "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
        "        return linear_output"
      ],
      "metadata": {
        "id": "gNxuEts_sqXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prediction "
      ],
      "metadata": {
        "id": "Y-mY0_52-w63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_hasbiasornot(text, labels_map_v, model_path):\n",
        "\n",
        "  if('Category' in model_path):\n",
        "    num_classes = 50\n",
        "  else:\n",
        "    num_classes = 2\n",
        "\n",
        "  model_new1 = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=num_classes, max_seq_len=128, gpt_model_name=\"gpt2\")\n",
        "  model_new1.load_state_dict(torch.load(model_path))\n",
        "  model_new1.eval()\n",
        "\n",
        "  fixed_text = \" \".join(text.lower().split())\n",
        "  # tokenize the text\n",
        "  tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "  tokenizer.padding_side = \"left\"\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  # create model input\n",
        "  model_input = tokenizer(fixed_text, padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "  mask = model_input['attention_mask'].cpu()\n",
        "  input_id = model_input[\"input_ids\"].squeeze(1).cpu()\n",
        "\n",
        "  output = model_new1(input_id, mask)\n",
        "  prob = torch.nn.functional.softmax(output, dim=1)[0]\n",
        "\n",
        "  labels_map = labels_map_v\n",
        "\n",
        "  pred_label = labels_map[output.argmax(dim=1).item()]\n",
        "\n",
        "  return pred_label"
      ],
      "metadata": {
        "id": "n5FJ5aAhtCfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Lables for each model prediction"
      ],
      "metadata": {
        "id": "E-ulcXZo-4Jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lables for offensive model\n",
        "labels_map_o = {\n",
        "      0: \"not offensive\",\n",
        "      1: \"offensive\"\n",
        "          }\n",
        "\n",
        "# lables for biased model\n",
        "labels_map_b = {\n",
        "      0: \"biased\",\n",
        "      1: \"unbiased\"\n",
        "          }\n",
        "\n",
        "# lables for category sterotype model\n",
        "labels_map_c = {'[]': 0, '[\"social\"]': 1, '[\"culture\"]': 2, '[\"culture\", \"gender\"]': 3, '[\"gender\"]': 4, '[\"disabled\"]': 5, '[\"race\"]': 6, '[\"victim\"]': 7, '[\"gender\", \"race\"]': 8, '[\"body\"]': 9, '[\"culture\", \"race\"]': 10, '[\"culture\", \"social\"]': 11, '[\"gender\", \"victim\"]': 12, '[\"disabled\", \"race\"]': 13, '[\"race\", \"victim\"]': 14, '[\"race\", \"social\"]': 15, '[\"gender\", \"social\"]': 16, '[\"culture\", \"victim\"]': 17, '[\"body\", \"gender\"]': 18, '[\"culture\", \"disabled\"]': 19, '[\"body\", \"race\"]': 20, '[\"culture\", \"race\", \"victim\"]': 21, '[\"disabled\", \"gender\"]': 22, '[\"social\", \"victim\"]': 23, '[\"gender\", \"race\", \"victim\"]': 24, '[\"body\", \"culture\"]': 25, '[\"body\", \"disabled\"]': 26, '[\"body\", \"victim\"]': 27, '[\"disabled\", \"victim\"]': 28, '[\"culture\", \"gender\", \"victim\"]': 29, '[\"body\", \"culture\", \"race\"]': 30, '[\"body\", \"social\"]': 31, '[\"culture\", \"disabled\", \"race\"]': 32, '[\"race\", \"social\", \"victim\"]': 33, '[\"disabled\", \"gender\", \"victim\"]': 34, '[\"disabled\", \"social\"]': 35, '[\"culture\", \"gender\", \"race\"]': 36, '[\"body\", \"gender\", \"victim\"]': 37, '[\"disabled\", \"gender\", \"race\"]': 38, '[\"gender\", \"race\", \"social\"]': 39, '[\"gender\", \"social\", \"victim\"]': 40, '[\"culture\", \"gender\", \"social\"]': 41, '[\"culture\", \"race\", \"social\"]': 42, '[\"body\", \"gender\", \"social\"]': 43, '[\"culture\", \"gender\", \"race\", \"social\"]': 44, '[\"culture\", \"social\", \"victim\"]': 45, '[\"body\", \"gender\", \"race\"]': 46, '[\"body\", \"disabled\", \"race\"]': 47, '[\"culture\", \"disabled\", \"victim\"]': 48, '[\"body\", \"disabled\", \"social\"]': 49}\n",
        "\n",
        "#labels_map_c\n",
        "labels_test_c = {}\n",
        "for k, v in labels_map_c.items():\n",
        "  key, value = k, v\n",
        "  labels_test_c[value] = k"
      ],
      "metadata": {
        "id": "p-xog2tswLRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Social Bias Indicator"
      ],
      "metadata": {
        "id": "nQ7t34LY_IqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def social_bias_indicator(model_type, input_text):\n",
        "  # /content/gdrive/My Drive/Colab Notebooks/models/Offensive.pt\n",
        "  if model_type == 'Offensive':\n",
        "\t  return predict_hasbiasornot(input_text, labels_map_o, \"/content/gdrive/My Drive/Colab Notebooks/models/Offensive.pt\")\n",
        "  if model_type == 'Category':\n",
        "    return predict_hasbiasornot(input_text, labels_test_c, \"/content/gdrive/My Drive/Colab Notebooks/models/Category.pt\")\n",
        "  if model_type == 'BiasImplication':\n",
        "    return predict_hasbiasornot(input_text, labels_map_b, \"/content/gdrive/My Drive/Colab Notebooks/models/BiasImplication.pt\")"
      ],
      "metadata": {
        "id": "wds5k2tktDHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. I thought drugs were the only things black people could shoot up Boy was I wrong\n",
        "\n",
        "2.  I hate fat bitches\n",
        "\n",
        "3.  ”Black guy in class: *attempts to throw a paper ball into the trash* *misses* Mrs. Mundy: ”You’re a disgrace to your race, Marcus”\n",
        "\n",
        "4. All-female casts bother me but I have literally never noticed the hundreds of movies with 0 female characters I have already watched\n",
        "\n",
        "5. Amercians hate Immigrants.\n",
        "\n",
        "6. You annoyed me every day for months you’re a fucking moron\n",
        "\n",
        "7. \"Love is like the wind, you can't see it but you can feel it.\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Affy7bQjxogB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the input component for Gradio since we are expecting 2 inputs\n",
        "\n",
        "Model_type = gr.Textbox(label = \"Enter the Model Type - Offensive, Category, BiasImplication\")\n",
        "input_text = gr.Textbox(label = \"Enter the Post/Comment/Tweet/Sentence\")\n",
        "# We create the output\n",
        "output = gr.Textbox()\n",
        "\n",
        "app = gr.Interface(fn = social_bias_indicator, inputs=[Model_type, input_text], outputs=output)\n",
        "app.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "ShLAnEBktoaO",
        "outputId": "be17f6da-6d7d-477b-ae4b-942427768ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://4355be877f26e20a.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4355be877f26e20a.gradio.app\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}